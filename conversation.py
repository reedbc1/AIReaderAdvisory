import json
import os

import faiss
import numpy as np
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

TOOLS = [{
    "type": "web_search",
}, {
    "type": "function",
    "name": "search_library",
    "description": "Find movies for the user based on what they say they are looking for.",
    "strict": True,
    "parameters": {
        "type": "object",
        "properties": {
            "query": {
                "type": "string",
                "description": (
                    "A description of what kinds of movies the customer is looking for,"
                    "including the names of movies and actors."
                )
            },
            "k": {
                "type": "integer",
                "description": "The number of top similar results to return.",
                "default": 5
            }
        },
        "required": ["query", "k"],
        "additionalProperties": False
    }
}]


def load_library(index_path="library.index", json_path="json_files/wr_enhanced.json"):
    """Load FAISS index and JSON records for interactive search."""

    index = faiss.read_index(index_path)
    with open(json_path, encoding="utf-8") as file:
        records = json.load(file)

    embeddings = np.load("library_embeddings.npy")
    assert len(records) == embeddings.shape[0], "‚ùå Mismatch between JSON records and embeddings!"
    return index, records


def search_library(query, k, index, records):
    """Return top-k most similar library items to a text query."""

    response = client.embeddings.create(model="text-embedding-3-small", input=query)
    query_vec = np.array(response.data[0].embedding, dtype="float32").reshape(1, -1)
    distances, indices = index.search(query_vec, k)

    results = []
    for dist, idx in zip(distances[0], indices[0]):
        record = records[idx]
        results.append({
            "title": record.get("title"),
            "author": record.get("author"),
            "material": record.get("materials", [])[0].get("name"),
            "year": record.get("publicationDate"),
            "summary": record.get("summary"),
            "subjects": record.get("subjects"),
            "contributors": record.get("contributors"),
            "distance": float(dist)
        })
    return results


def call_function(name, args, *, index, records):
    if name == "search_library":
        return search_library(**args, index=index, records=records)
    raise ValueError(f"Unknown tool: {name}")


def create_conversation():
    conversation = client.conversations.create()
    return conversation.id


def run_conversation_loop():
    index, records = load_library()
    conv_id = create_conversation()

    while True:
        query = str(input("Enter query (or 'exit' to quit): "))
        if query.lower() == "exit":
            break

        input_messages = [{"role": "user", "content": f"{query}"}]
        response = client.responses.create(model="gpt-5", tools=TOOLS, input=input_messages, conversation=conv_id)

        for tool_call in response.output:
            if tool_call.type == "function_call":
                name = tool_call.name
                args = json.loads(tool_call.arguments)
                result = call_function(name, args, index=index, records=records)

                client.conversations.items.create(
                    conv_id,
                    items=[{
                        "type": "function_call_output",
                        "call_id": tool_call.call_id,
                        "output": str(result)
                    }]
                )

                response = client.responses.create(
                    model="gpt-5",
                    input="pick 3 of the movies generated by a tool and explain how they match the query.",
                    conversation=conv_id
                )

        print(response.output_text)


if __name__ == "__main__":
    run_conversation_loop()
